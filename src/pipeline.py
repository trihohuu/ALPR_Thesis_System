import cv2
import os
import time

# Import c√°c module core
from core.detector import PlateDetector
from core.ocr_paddle import LicensePlateOCR
from core.image_utils import preprocess_plate, draw_results

class ALPRPipeline:
    def __init__(self, yolo_path, use_gpu=True):
        print("ƒêang kh·ªüi t·∫°o h·ªá th·ªëng ALPR...")
        
        # 1. Kh·ªüi t·∫°o Detector (YOLO)
        if not os.path.exists(yolo_path):
            raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y model YOLO t·∫°i: {yolo_path}")
        self.detector = PlateDetector(model_path=yolo_path)
        
        # 2. Kh·ªüi t·∫°o OCR (Paddle)
        self.ocr = LicensePlateOCR(use_gpu=use_gpu)
        
        print("H·ªá th·ªëng ƒë√£ s·∫µn s√†ng!")

    def run(self, source_path, show=True, save_path=None):
        """
        Ch·∫°y quy tr√¨nh tr√™n 1 ·∫£nh ho·∫∑c video
        :param source_path: ƒê∆∞·ªùng d·∫´n ·∫£nh
        """
        # ƒê·ªçc ·∫£nh
        frame = cv2.imread(source_path)
        if frame is None:
            print(f" Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {source_path}")
            return

        start_time = time.time()

        # B∆Ø·ªöC 1: Detect bi·ªÉn s·ªë
        detections = self.detector.detect(frame)
        print(f"üîç Ph√°t hi·ªán {len(detections)} bi·ªÉn s·ªë.")

        # B∆Ø·ªöC 2: Loop qua t·ª´ng bi·ªÉn s·ªë ƒë·ªÉ OCR
        final_results = []
        for item in detections:
            plate_img = item['plate_img']
            
            # Ti·ªÅn x·ª≠ l√Ω ·∫£nh (Ph√≥ng to, l√†m r√µ)
            processed_plate = preprocess_plate(plate_img)
            
            # OCR
            text, conf = self.ocr.predict(processed_plate)
            
            # L∆∞u k·∫øt qu·∫£ l·∫°i v√†o dict
            item['text'] = text
            item['ocr_conf'] = conf
            final_results.append(item)
            
            print(f"   -> Bi·ªÉn s·ªë: {text} (Conf: {conf:.2f})")

        end_time = time.time()
        fps = 1 / (end_time - start_time)
        print(f"‚è±Ô∏è Th·ªùi gian x·ª≠ l√Ω: {end_time - start_time:.4f}s")

        # B∆Ø·ªöC 3: V·∫Ω v√† Hi·ªÉn th·ªã
        result_image = draw_results(frame, final_results)

        if save_path:
            cv2.imwrite(save_path, result_image)
            print(f"üíæ ƒê√£ l∆∞u k·∫øt qu·∫£ t·∫°i: {save_path}")

        if show:
            # Resize hi·ªÉn th·ªã n·∫øu ·∫£nh qu√° to
            h, w = result_image.shape[:2]
            if w > 1200:
                result_image = cv2.resize(result_image, (1200, int(1200*h/w)))
            
            cv2.imshow("ALPR Result", result_image)
            cv2.waitKey(0)
            cv2.destroyAllWindows()

# ==========================================
# PH·∫¶N TEST NHANH (ENTRY POINT)
# ==========================================
if __name__ == "__main__":
    # C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n
    # S·ª≠a l·∫°i ƒë∆∞·ªùng d·∫´n model YOLO c·ªßa b·∫°n cho ƒë√∫ng
    CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
    MODEL_PATH = os.path.join(CURRENT_DIR, '..', 'models', 'yolo', 'weights', 'best.pt')
    
    # ·∫¢nh test
    IMAGE_PATH = os.path.join(CURRENT_DIR, '..', 'assets', 'test_image.jpg')

    try:
        # Kh·ªüi t·∫°o pipeline
        app = ALPRPipeline(yolo_path=MODEL_PATH, use_gpu=False)
        
        # Ch·∫°y
        app.run(IMAGE_PATH, save_path=os.path.join(CURRENT_DIR, '..', 'output', 'final_result.jpg'))
        
    except Exception as e:
        print(f"C√≥ l·ªói x·∫£y ra: {e}")